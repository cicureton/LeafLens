# -*- coding: utf-8 -*-
"""model_train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kk7A1clhxm87BOhY4v0GVqqyQQHXunZp
"""

import torch
import torch.nn as nn
from torchvision import models

# Load pretrained MobileNetV3
mobilenet_v3_large = models.mobilenet_v3_large(weights="IMAGENET1K_V2")

# Remove ImageNet classifier
mobilenet_v3_large.classifier = nn.Identity()

# Freeze early layers so we just train the last convolutional layers
for param in mobilenet_v3_large.features[:-10].parameters():
    param.requires_grad = False

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device);
mobilenet_v3_large.to(device)

import pandas as pd
subset_metadata = pd.read_csv('/home/abcrubaugh/data/subset_metadata.csv', low_memory=False)

# Check subset_metadata information (20 species, 8450 unique images)
print(subset_metadata.shape)
print(subset_metadata.nunique())

# import os
# import requests
# from concurrent.futures import ThreadPoolExecutor

# # Create directory to store my subset dataset images
# os.makedirs('/home/abcrubaugh/data/subset_images', exist_ok=True)

# # Function to download images
# def download_image(url):
#     filename = os.path.join("/home/abcrubaugh/data/subset_images", os.path.basename(url))
#     if not os.path.exists(filename):
#         r = requests.get(url, timeout=10)
#         if r.status_code == 200:
#             r = requests.get(url)
#             with open(filename, "wb") as f:
#                 f.write(r.content)

# # list all the urls in subset_metadata to download
# urls = subset_metadata["url"].tolist()

# # Increase # of threads operating the downloads (26)
# with ThreadPoolExecutor(max_workers=26) as executor:
#     list(executor.map(download_image, urls))

from re import X
from sklearn.model_selection import train_test_split
# initialize train/test/val split for our model

# initialize train/val and test to split our subset metadata into 80% and 20%
X_temp, X_test, y_temp, y_test = train_test_split(subset_metadata["url"], subset_metadata["species"], test_size=0.2, random_state=42, stratify=subset_metadata["species"])
# split train/val into 60/20 by giving validation size 25% of 80 = 20
X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp)


print(f"Train size: {len(X_train)}")
print(f"Validation size: {len(X_val)}")
print(f"Test size: {len(X_test)}")

import os

image_folder = "/home/abcrubaugh/data/subset_images/"
# Change the datasets to correct localpaths (because i split the datasets using the url attribute) to local filepath (otherwise error will occur when trying to train model (could not find https://lasjfldja))
train_images = [os.path.join(image_folder, os.path.basename(url)) for url in X_train]
val_images   = [os.path.join(image_folder, os.path.basename(url)) for url in X_val]
test_images  = [os.path.join(image_folder, os.path.basename(url)) for url in X_test]

# Reset index back to sequential because after splitting train-val-test they may not be sequential anymore
y_train = y_train.reset_index(drop=True)
y_val   = y_val.reset_index(drop=True)
y_test  = y_test.reset_index(drop=True)

from torch.utils.data import Dataset
from PIL import Image
import os
# Create a custom dataset to house our training data (pytorch models needs tensors not csv/url files which the images are currently in)
class PlantDatasetLocal(Dataset):
    def __init__(self, image_paths, labels, transform=None):
        self.image_paths = image_paths
        self.labels = labels.reset_index(drop=True)
        self.transform = transform
        self.classes = sorted(self.labels.unique())
        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}
        self.image_directory = "/home/abcrubaugh/data/subset_images/image_data" # Add image directory

    def __len__(self):
        return len(self.image_paths)

# How to get individual items in the plantdatasetLocal
    def __getitem__(self, idx):
        # Construct local file path
        image_name = os.path.basename(self.image_paths[idx])
        image_path = os.path.join(self.image_directory, image_name)
        image = Image.open(image_path).convert("RGB")
        label = self.class_to_idx[self.labels[idx]]

        if self.transform:
            image = self.transform(image)

        return image, label

from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# Define data transformation (how the model can intepret the data. Must be 224x224 and tensor object 0-1 instead of 0-255 pixel values)
# and normalized as well
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomVerticalFlip(),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# Our labels must be reset to pd.series and reset index after changing them to
# python lists when we cleaned them for missing/corrupted data
y_train = pd.Series(y_train).reset_index(drop=True)
y_val = pd.Series(y_val).reset_index(drop=True)
y_test = pd.Series(y_test).reset_index(drop=True)


# Create the custom train dataset using torchvision to transform our data into something apprehendable by the model (not csv, not just img urls)
train_dataset = PlantDatasetLocal(train_images, y_train, transform=transform)
val_dataset = PlantDatasetLocal(val_images, y_val, transform=transform)
test_dataset = PlantDatasetLocal(test_images, y_test, transform=transform)
# Create the train loader with a batch size of 32 that we will pass through the moddle each time, shuffled.
# Increased the num_workers to try and increase the speed
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)

# Determine the number of unique species
num_species = len(train_dataset.classes)
print(f"Number of unique species: {num_species}")

import torch.optim as optim
import torch.optim.lr_scheduler as lr_scheduler


# Loss function and optimizier
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(mobilenet_v3_large.parameters(), lr=0.001)
scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)
print("Training!")
# Training Loop using x epochs (seven run throughs of the same dataset)
num_epochs = 20
patience = 5
min_delta = 0.001

best_val_loss = float("inf")
counter = 0

for epoch in range(num_epochs):
    mobilenet_v3_large.train()
    running_loss = 0.0
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()

        # Forward pass calculates the output by feeding input thorugh model nad loss using criterion function
        outputs = mobilenet_v3_large(inputs)
        loss = criterion(outputs, labels)

        # Backward pass and optimization
        loss.backward()
        optimizer.step()

        running_loss += loss.item()


    scheduler.step()

    # Average loss for the epoch
    epoch_loss = running_loss / len(train_loader)

    # evaluation mode
    mobilenet_v3_large.eval()
    val_loss = 0.0
    correct = 0
    total = 0
    # No gradient calculation
    with torch.no_grad():
        for inputs, labels in val_loader:  # tqdm removed
            inputs, labels = inputs.to(device), labels.to(device)
            # Forward pass
            outputs = mobilenet_v3_large(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item()

            # Get class with highest score
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    val_loss = val_loss / len(val_loader)
    val_accuracy = 100 * correct / total

    print(f"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}")
    print(f"Validation Accuracy: {val_accuracy:.2f}%")

    if val_loss < best_val_loss - min_delta:
        best_val_loss = val_loss
        counter = 0
    else:
        counter += 1
        if counter >= patience:
            print("Early stopped!")
            break

torch.save(mobilenet_v3_large.state_dict(), "/home/abcrubaugh/mobilenet_v3_large_plants.pth")
print("Model saved")

mobilenet_v3_large.eval()  # evaluation mode
correct = 0
total = 0
# No gradient calculation
with torch.no_grad():
    for inputs, labels in test_loader:  # tqdm removed
        inputs, labels = inputs.to(device), labels.to(device)
        # Forward pass
        outputs = mobilenet_v3_large(inputs)
        # Get class with highest score
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f"Test Accuracy: {100 * correct / total:.2f}%")

